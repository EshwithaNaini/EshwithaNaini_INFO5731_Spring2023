{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EshwithaNaini/EshwithaNaini_INFO5731_Spring2023/blob/main/In_class_exercise_03_02282023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGNFDtAuvTZ3"
      },
      "source": [
        "## The third In-class-exercise (2/28/2023, 40 points in total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVmGB11_vTZ5"
      },
      "source": [
        "The purpose of this exercise is to understand text representation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6h9QPnHvTZ5"
      },
      "source": [
        "Question 1 (10 points): Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoRq_gn7vTZ6"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Please write you answer here:\n",
        "A fun text classification task would be to categorize positive and negative customer reviews of a product. This task can help businesses understand how their customers feel about their products and services, allowing them to improve their offerings.\n",
        "\n",
        "We can build a machine learning model for this task using a variety of features, including:\n",
        "\n",
        "Bag of Words (BoW): This feature represents each word's occurrence in the text, regardless of order of appearance. The BoW feature is useful because it tracks the frequency of words indicating positive or negative sentiment.\n",
        "\n",
        "N-grams are contiguous textual sequences of n words. Using n-grams can help you capture contextual information about words.\n",
        "\n",
        "POS tagging: This feature assigns each word a part of speech, such as noun, verb, adjective, and so on. POS tagging can aid in the identification of sentiment-bearing words such as adjectives and adverbs.\n",
        "\n",
        "Sentiment lexicons are pre-defined lists of positive or negative words or phrases. Including sentiment lexicons as features can help the model better identify a text's sentiment.\n",
        "\n",
        "Punctuation and capitalization: These elements can help convey the intensity of the text's emotion. A message conveyed in all caps, for example, may be more powerful.\n",
        "\n",
        "Finally, we can create a more accurate and robust machine learning model by incorporating features such as BoW, N-grams, POS tagging, sentiment lexicons, and punctuation and capitalization.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PC9vtKOvTZ7"
      },
      "source": [
        "Question 2 (10 points): Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJFZjlUzvTZ7",
        "outputId": "514430e5-2451-4c8d-bc13-c9262718543e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: I really enjoyed the movie, it was great!\n",
            "Bag of Words: {'i': 1, 'really': 1, 'enjoyed': 1, 'movie': 1, 'great': 1}\n",
            "Bigrams: [('i', 'really'), ('really', 'enjoyed'), ('enjoyed', 'movie'), ('movie', 'great')]\n",
            "POS Tagging: [('I', 'PRP'), ('really', 'RB'), ('enjoyed', 'VBD'), ('the', 'DT'), ('movie', 'NN'), (',', ','), ('it', 'PRP'), ('was', 'VBD'), ('great', 'JJ'), ('!', '.')]\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.385, 'pos': 0.615, 'compound': 0.8395}\n",
            "Punctuation: {'exclamations': 1, 'question_marks': 0, 'total_punctuations': 1}\n",
            "\n",
            "Text: The food was terrible, I would not recommend it to anyone.\n",
            "Bag of Words: {'the': 1, 'food': 1, 'terrible': 1, 'i': 1, 'would': 1, 'recommend': 1, 'anyone': 1}\n",
            "Bigrams: [('the', 'food'), ('food', 'terrible'), ('terrible', 'i'), ('i', 'would'), ('would', 'recommend'), ('recommend', 'anyone')]\n",
            "POS Tagging: [('The', 'DT'), ('food', 'NN'), ('was', 'VBD'), ('terrible', 'JJ'), (',', ','), ('I', 'PRP'), ('would', 'MD'), ('not', 'RB'), ('recommend', 'VB'), ('it', 'PRP'), ('to', 'TO'), ('anyone', 'NN'), ('.', '.')]\n",
            "Sentiment: {'neg': 0.394, 'neu': 0.606, 'pos': 0.0, 'compound': -0.6381}\n",
            "Punctuation: {'exclamations': 0, 'question_marks': 0, 'total_punctuations': 0}\n",
            "\n",
            "Text: The customer service was excellent, very friendly staff.\n",
            "Bag of Words: {'the': 1, 'customer': 1, 'service': 1, 'excellent': 1, 'friendly': 1, 'staff': 1}\n",
            "Bigrams: [('the', 'customer'), ('customer', 'service'), ('service', 'excellent'), ('excellent', 'friendly'), ('friendly', 'staff')]\n",
            "POS Tagging: [('The', 'DT'), ('customer', 'NN'), ('service', 'NN'), ('was', 'VBD'), ('excellent', 'JJ'), (',', ','), ('very', 'RB'), ('friendly', 'JJ'), ('staff', 'NN'), ('.', '.')]\n",
            "Sentiment: {'neg': 0.0, 'neu': 0.455, 'pos': 0.545, 'compound': 0.8016}\n",
            "Punctuation: {'exclamations': 0, 'question_marks': 0, 'total_punctuations': 0}\n",
            "\n",
            "Text: The product was not what I expected, I was disappointed.\n",
            "Bag of Words: {'the': 1, 'product': 1, 'i': 2, 'expected': 1, 'disappointed': 1}\n",
            "Bigrams: [('the', 'product'), ('product', 'i'), ('i', 'expected'), ('expected', 'i'), ('i', 'disappointed')]\n",
            "POS Tagging: [('The', 'DT'), ('product', 'NN'), ('was', 'VBD'), ('not', 'RB'), ('what', 'WP'), ('I', 'PRP'), ('expected', 'VBD'), (',', ','), ('I', 'PRP'), ('was', 'VBD'), ('disappointed', 'VBN'), ('.', '.')]\n",
            "Sentiment: {'neg': 0.307, 'neu': 0.693, 'pos': 0.0, 'compound': -0.4767}\n",
            "Punctuation: {'exclamations': 0, 'question_marks': 0, 'total_punctuations': 0}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Sample text data\n",
        "text_data = [\"I really enjoyed the movie, it was great!\",              \"The food was terrible, I would not recommend it to anyone.\",             \"The customer service was excellent, very friendly staff.\",             \"The product was not what I expected, I was disappointed.\"]\n",
        "\n",
        "# Define functions for feature extraction\n",
        "def bag_of_words(text):\n",
        "    words = word_tokenize(text)\n",
        "    words = [word.lower() for word in words if word.isalpha() and word not in stopwords.words(\"english\")]\n",
        "    return dict(nltk.FreqDist(words))\n",
        "\n",
        "def ngrams(text, n=2):\n",
        "    words = word_tokenize(text)\n",
        "    words = [word.lower() for word in words if word.isalpha() and word not in stopwords.words(\"english\")]\n",
        "    return list(nltk.ngrams(words, n))\n",
        "\n",
        "def pos_tagging(text):\n",
        "    words = word_tokenize(text)\n",
        "    return nltk.pos_tag(words)\n",
        "\n",
        "def sentiment(text):\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "    return sia.polarity_scores(text)\n",
        "\n",
        "def punctuation(text):\n",
        "    num_exclamations = text.count('!')\n",
        "    num_question_marks = text.count('?')\n",
        "    num_punctuations = num_exclamations + num_question_marks\n",
        "    return {'exclamations': num_exclamations, 'question_marks': num_question_marks, 'total_punctuations': num_punctuations}\n",
        "\n",
        "# Example usage\n",
        "for text in text_data:\n",
        "    print(\"Text:\", text)\n",
        "    print(\"Bag of Words:\", bag_of_words(text))\n",
        "    print(\"Bigrams:\", ngrams(text, n=2))\n",
        "    print(\"POS Tagging:\", pos_tagging(text))\n",
        "    print(\"Sentiment:\", sentiment(text))\n",
        "    print(\"Punctuation:\", punctuation(text))\n",
        "    print(\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUKHKngevTZ8"
      },
      "source": [
        "Question 3 (10 points): Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\" Select the most important features you extracted above, rank the features based on their importance in the descending order. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJ8pSzL4vTZ9",
        "outputId": "aa79efce-e665-4edc-b80c-350539a7d151"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 features with the highest MI scores:\n",
            "not 0.8333333333333331\n",
            "the 0.8333333333333331\n",
            "service 0.45833333333333315\n",
            "disappointed 0.20833333333333315\n",
            "enjoyed 0.20833333333333315\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Applications/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Convert the text data into feature vectors using bag of words\n",
        "corpus = []\n",
        "for text in text_data:\n",
        "    corpus.append(' '.join(word_tokenize(text)))\n",
        "    \n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(corpus).toarray()\n",
        "y = np.array([1, 0, 1, 0])  # Positive reviews are labeled as 1, negative reviews are labeled as 0\n",
        "\n",
        "# Compute the MI scores for each feature\n",
        "mi_scores = mutual_info_classif(X, y)\n",
        "\n",
        "# Create a dictionary of feature name and MI score pairs\n",
        "feature_scores = dict(zip(vectorizer.get_feature_names(), mi_scores))\n",
        "\n",
        "# Rank the features based on their importance in the descending order\n",
        "ranked_features = sorted(feature_scores, key=feature_scores.get, reverse=True)\n",
        "\n",
        "# Print the top 5 features with the highest MI scores\n",
        "print(\"Top 5 features with the highest MI scores:\")\n",
        "for feature in ranked_features[:5]:\n",
        "    print(feature, feature_scores[feature])\n",
        "print"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSDsTjqdvTZ9"
      },
      "source": [
        "Question 4 (10 points): Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy-ATIvVD8OP",
        "outputId": "75fc062a-3aa8-4c4f-8d73-2edccf0a251c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.1-py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 KB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip list\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_Be0DJ2EEhv",
        "outputId": "58b45d3a-f66b-4866-efab-8703c175c0a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Package                       Version\n",
            "----------------------------- --------------------\n",
            "absl-py                       1.4.0\n",
            "aeppl                         0.0.33\n",
            "aesara                        2.7.9\n",
            "alabaster                     0.7.13\n",
            "albumentations                1.2.1\n",
            "altair                        4.2.2\n",
            "argon2-cffi                   21.3.0\n",
            "argon2-cffi-bindings          21.2.0\n",
            "arviz                         0.12.1\n",
            "astropy                       4.3.1\n",
            "astunparse                    1.6.3\n",
            "atomicwrites                  1.4.1\n",
            "attrs                         22.2.0\n",
            "audioread                     3.0.0\n",
            "autograd                      1.5\n",
            "Babel                         2.12.1\n",
            "backcall                      0.2.0\n",
            "backports.zoneinfo            0.2.1\n",
            "beautifulsoup4                4.6.3\n",
            "bleach                        6.0.0\n",
            "blis                          0.7.9\n",
            "bokeh                         2.4.3\n",
            "branca                        0.6.0\n",
            "bs4                           0.0.1\n",
            "CacheControl                  0.12.11\n",
            "cachetools                    5.3.0\n",
            "catalogue                     2.0.8\n",
            "certifi                       2022.12.7\n",
            "cffi                          1.15.1\n",
            "cftime                        1.6.2\n",
            "chardet                       4.0.0\n",
            "click                         8.1.3\n",
            "cloudpickle                   2.2.1\n",
            "cmake                         3.22.6\n",
            "cmdstanpy                     1.1.0\n",
            "colorcet                      3.0.1\n",
            "colorlover                    0.3.0\n",
            "community                     1.0.0b1\n",
            "confection                    0.0.4\n",
            "cons                          0.4.5\n",
            "contextlib2                   0.5.5\n",
            "convertdate                   2.4.0\n",
            "cufflinks                     0.17.3\n",
            "cvxopt                        1.3.0\n",
            "cvxpy                         1.2.3\n",
            "cycler                        0.11.0\n",
            "cymem                         2.0.7\n",
            "Cython                        0.29.33\n",
            "dask                          2022.2.1\n",
            "datascience                   0.17.6\n",
            "db-dtypes                     1.0.5\n",
            "dbus-python                   1.2.16\n",
            "debugpy                       1.6.6\n",
            "decorator                     4.4.2\n",
            "defusedxml                    0.7.1\n",
            "distributed                   2022.2.1\n",
            "dlib                          19.24.0\n",
            "dm-tree                       0.1.8\n",
            "dnspython                     2.3.0\n",
            "docutils                      0.16\n",
            "dopamine-rl                   1.0.5\n",
            "earthengine-api               0.1.343\n",
            "easydict                      1.10\n",
            "ecos                          2.0.12\n",
            "editdistance                  0.5.3\n",
            "en-core-web-sm                3.4.1\n",
            "entrypoints                   0.4\n",
            "ephem                         4.1.4\n",
            "et-xmlfile                    1.1.0\n",
            "etils                         1.0.0\n",
            "etuples                       0.3.8\n",
            "fastai                        2.7.11\n",
            "fastcore                      1.5.28\n",
            "fastdownload                  0.0.7\n",
            "fastjsonschema                2.16.3\n",
            "fastprogress                  1.0.3\n",
            "fastrlock                     0.8.1\n",
            "filelock                      3.9.0\n",
            "firebase-admin                5.3.0\n",
            "fix-yahoo-finance             0.0.22\n",
            "Flask                         2.2.3\n",
            "flatbuffers                   23.3.3\n",
            "folium                        0.12.1.post1\n",
            "fonttools                     4.39.0\n",
            "fsspec                        2023.3.0\n",
            "future                        0.16.0\n",
            "gast                          0.4.0\n",
            "GDAL                          3.3.2\n",
            "gdown                         4.4.0\n",
            "gensim                        3.6.0\n",
            "geographiclib                 1.52\n",
            "geopy                         1.17.0\n",
            "gin-config                    0.5.0\n",
            "glob2                         0.7\n",
            "google                        2.0.3\n",
            "google-api-core               2.11.0\n",
            "google-api-python-client      2.70.0\n",
            "google-auth                   2.16.2\n",
            "google-auth-httplib2          0.1.0\n",
            "google-auth-oauthlib          0.4.6\n",
            "google-cloud-bigquery         3.4.2\n",
            "google-cloud-bigquery-storage 2.19.0\n",
            "google-cloud-core             2.3.2\n",
            "google-cloud-datastore        2.11.1\n",
            "google-cloud-firestore        2.7.3\n",
            "google-cloud-language         2.6.1\n",
            "google-cloud-storage          2.7.0\n",
            "google-cloud-translate        3.8.4\n",
            "google-colab                  1.0.0\n",
            "google-crc32c                 1.5.0\n",
            "google-pasta                  0.2.0\n",
            "google-resumable-media        2.4.1\n",
            "googleapis-common-protos      1.58.0\n",
            "googledrivedownloader         0.4\n",
            "graphviz                      0.10.1\n",
            "greenlet                      2.0.2\n",
            "grpcio                        1.51.3\n",
            "grpcio-status                 1.48.2\n",
            "gspread                       3.4.2\n",
            "gspread-dataframe             3.0.8\n",
            "gym                           0.25.2\n",
            "gym-notices                   0.0.8\n",
            "h5py                          3.1.0\n",
            "HeapDict                      1.0.1\n",
            "hijri-converter               2.2.4\n",
            "holidays                      0.21\n",
            "holoviews                     1.14.9\n",
            "html5lib                      1.0.1\n",
            "httpimport                    0.5.18\n",
            "httplib2                      0.17.4\n",
            "huggingface-hub               0.13.1\n",
            "humanize                      0.5.1\n",
            "hyperopt                      0.1.2\n",
            "idna                          2.10\n",
            "imageio                       2.9.0\n",
            "imagesize                     1.4.1\n",
            "imbalanced-learn              0.8.1\n",
            "imblearn                      0.0\n",
            "imgaug                        0.4.0\n",
            "importlib-metadata            6.0.0\n",
            "importlib-resources           5.12.0\n",
            "imutils                       0.5.4\n",
            "inflect                       2.1.0\n",
            "intel-openmp                  2023.0.0\n",
            "ipykernel                     5.3.4\n",
            "ipython                       7.9.0\n",
            "ipython-genutils              0.2.0\n",
            "ipython-sql                   0.3.9\n",
            "ipywidgets                    7.7.1\n",
            "itsdangerous                  2.1.2\n",
            "jax                           0.4.4\n",
            "jaxlib                        0.4.4+cuda11.cudnn82\n",
            "jieba                         0.42.1\n",
            "Jinja2                        3.1.2\n",
            "joblib                        1.2.0\n",
            "jsonschema                    4.3.3\n",
            "jupyter-client                6.1.12\n",
            "jupyter-console               6.1.0\n",
            "jupyter_core                  5.2.0\n",
            "jupyterlab-pygments           0.2.2\n",
            "jupyterlab-widgets            3.0.5\n",
            "kaggle                        1.5.13\n",
            "keras                         2.11.0\n",
            "keras-vis                     0.4.1\n",
            "kiwisolver                    1.4.4\n",
            "korean-lunar-calendar         0.3.1\n",
            "langcodes                     3.3.0\n",
            "libclang                      15.0.6.1\n",
            "librosa                       0.8.1\n",
            "lightgbm                      2.2.3\n",
            "llvmlite                      0.39.1\n",
            "locket                        1.0.0\n",
            "logical-unification           0.4.5\n",
            "LunarCalendar                 0.0.9\n",
            "lxml                          4.9.2\n",
            "Markdown                      3.4.1\n",
            "MarkupSafe                    2.1.2\n",
            "matplotlib                    3.5.3\n",
            "matplotlib-venn               0.11.9\n",
            "miniKanren                    1.0.3\n",
            "missingno                     0.5.2\n",
            "mistune                       0.8.4\n",
            "mizani                        0.8.1\n",
            "mkl                           2019.0\n",
            "mlxtend                       0.14.0\n",
            "more-itertools                9.1.0\n",
            "moviepy                       0.2.3.5\n",
            "mpmath                        1.2.1\n",
            "msgpack                       1.0.4\n",
            "multipledispatch              0.6.0\n",
            "multitasking                  0.0.11\n",
            "murmurhash                    1.0.9\n",
            "music21                       5.5.0\n",
            "natsort                       5.5.0\n",
            "nbclient                      0.7.2\n",
            "nbconvert                     6.5.4\n",
            "nbformat                      5.7.3\n",
            "netCDF4                       1.6.3\n",
            "networkx                      3.0\n",
            "nibabel                       3.0.2\n",
            "nltk                          3.7\n",
            "notebook                      6.3.0\n",
            "numba                         0.56.4\n",
            "numexpr                       2.8.4\n",
            "numpy                         1.22.4\n",
            "oauth2client                  4.1.3\n",
            "oauthlib                      3.2.2\n",
            "opencv-contrib-python         4.6.0.66\n",
            "opencv-python                 4.6.0.66\n",
            "opencv-python-headless        4.7.0.72\n",
            "openpyxl                      3.0.10\n",
            "opt-einsum                    3.3.0\n",
            "osqp                          0.6.2.post0\n",
            "packaging                     23.0\n",
            "palettable                    3.3.0\n",
            "pandas                        1.3.5\n",
            "pandas-datareader             0.9.0\n",
            "pandas-gbq                    0.17.9\n",
            "pandas-profiling              1.4.1\n",
            "pandocfilters                 1.5.0\n",
            "panel                         0.14.4\n",
            "param                         1.12.3\n",
            "parso                         0.8.3\n",
            "partd                         1.3.0\n",
            "pathlib                       1.0.1\n",
            "pathy                         0.10.1\n",
            "patsy                         0.5.3\n",
            "pep517                        0.13.0\n",
            "pexpect                       4.8.0\n",
            "pickleshare                   0.7.5\n",
            "Pillow                        8.4.0\n",
            "pip                           22.0.4\n",
            "pip-tools                     6.6.2\n",
            "platformdirs                  3.1.0\n",
            "plotly                        5.5.0\n",
            "plotnine                      0.10.1\n",
            "pluggy                        0.7.1\n",
            "pooch                         1.7.0\n",
            "portpicker                    1.3.9\n",
            "prefetch-generator            1.0.3\n",
            "preshed                       3.0.8\n",
            "prettytable                   3.6.0\n",
            "progressbar2                  3.38.0\n",
            "prometheus-client             0.16.0\n",
            "promise                       2.3\n",
            "prompt-toolkit                2.0.10\n",
            "prophet                       1.1.2\n",
            "proto-plus                    1.22.2\n",
            "protobuf                      3.19.6\n",
            "psutil                        5.4.8\n",
            "psycopg2                      2.9.5\n",
            "ptyprocess                    0.7.0\n",
            "py                            1.11.0\n",
            "pyarrow                       9.0.0\n",
            "pyasn1                        0.4.8\n",
            "pyasn1-modules                0.2.8\n",
            "pycocotools                   2.0.6\n",
            "pycparser                     2.21\n",
            "pyct                          0.5.0\n",
            "pydantic                      1.10.5\n",
            "pydata-google-auth            1.7.0\n",
            "pydot                         1.3.0\n",
            "pydot-ng                      2.0.0\n",
            "pydotplus                     2.0.2\n",
            "PyDrive                       1.3.1\n",
            "pyerfa                        2.0.0.1\n",
            "Pygments                      2.6.1\n",
            "PyGObject                     3.36.0\n",
            "pymc                          4.1.4\n",
            "PyMeeus                       0.5.12\n",
            "pymongo                       4.3.3\n",
            "pymystem3                     0.2.0\n",
            "PyOpenGL                      3.1.6\n",
            "pyparsing                     3.0.9\n",
            "pyrsistent                    0.19.3\n",
            "PySocks                       1.7.1\n",
            "pytest                        3.6.4\n",
            "python-apt                    0.0.0\n",
            "python-dateutil               2.8.2\n",
            "python-louvain                0.16\n",
            "python-slugify                8.0.1\n",
            "python-utils                  3.5.2\n",
            "pytz                          2022.7.1\n",
            "pytz-deprecation-shim         0.1.0.post0\n",
            "pyviz-comms                   2.2.1\n",
            "PyWavelets                    1.4.1\n",
            "PyYAML                        6.0\n",
            "pyzmq                         23.2.1\n",
            "qdldl                         0.1.5.post3\n",
            "qudida                        0.0.4\n",
            "regex                         2022.6.2\n",
            "requests                      2.25.1\n",
            "requests-oauthlib             1.3.1\n",
            "requests-unixsocket           0.2.0\n",
            "resampy                       0.4.2\n",
            "rpy2                          3.5.5\n",
            "rsa                           4.9\n",
            "scikit-image                  0.19.3\n",
            "scikit-learn                  1.2.1\n",
            "scipy                         1.10.1\n",
            "screen-resolution-extra       0.0.0\n",
            "scs                           3.2.2\n",
            "seaborn                       0.11.2\n",
            "Send2Trash                    1.8.0\n",
            "setuptools                    57.4.0\n",
            "shapely                       2.0.1\n",
            "six                           1.15.0\n",
            "sklearn-pandas                2.2.0\n",
            "smart-open                    6.3.0\n",
            "snowballstemmer               2.2.0\n",
            "sortedcontainers              2.4.0\n",
            "soundfile                     0.12.1\n",
            "spacy                         3.4.4\n",
            "spacy-legacy                  3.0.12\n",
            "spacy-loggers                 1.0.4\n",
            "Sphinx                        3.5.4\n",
            "sphinxcontrib-applehelp       1.0.4\n",
            "sphinxcontrib-devhelp         1.0.2\n",
            "sphinxcontrib-htmlhelp        2.0.1\n",
            "sphinxcontrib-jsmath          1.0.1\n",
            "sphinxcontrib-qthelp          1.0.3\n",
            "sphinxcontrib-serializinghtml 1.1.5\n",
            "SQLAlchemy                    1.4.46\n",
            "sqlparse                      0.4.3\n",
            "srsly                         2.4.6\n",
            "statsmodels                   0.13.5\n",
            "sympy                         1.7.1\n",
            "tables                        3.7.0\n",
            "tabulate                      0.8.10\n",
            "tblib                         1.7.0\n",
            "tenacity                      8.2.2\n",
            "tensorboard                   2.11.2\n",
            "tensorboard-data-server       0.6.1\n",
            "tensorboard-plugin-wit        1.8.1\n",
            "tensorflow                    2.11.0\n",
            "tensorflow-datasets           4.8.3\n",
            "tensorflow-estimator          2.11.0\n",
            "tensorflow-gcs-config         2.11.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-io-gcs-filesystem  0.31.0\n",
            "tensorflow-metadata           1.12.0\n",
            "tensorflow-probability        0.19.0\n",
            "termcolor                     2.2.0\n",
            "terminado                     0.17.1\n",
            "text-unidecode                1.3\n",
            "textblob                      0.15.3\n",
            "thinc                         8.1.8\n",
            "threadpoolctl                 3.1.0\n",
            "tifffile                      2023.2.28\n",
            "tinycss2                      1.2.1\n",
            "tokenizers                    0.13.2\n",
            "toml                          0.10.2\n",
            "tomli                         2.0.1\n",
            "toolz                         0.12.0\n",
            "torch                         1.13.1+cu116\n",
            "torchaudio                    0.13.1+cu116\n",
            "torchsummary                  1.5.1\n",
            "torchtext                     0.14.1\n",
            "torchvision                   0.14.1+cu116\n",
            "tornado                       6.2\n",
            "tqdm                          4.65.0\n",
            "traitlets                     5.7.1\n",
            "transformers                  4.26.1\n",
            "tweepy                        3.10.0\n",
            "typer                         0.7.0\n",
            "typing_extensions             4.5.0\n",
            "tzdata                        2022.7\n",
            "tzlocal                       4.2\n",
            "uritemplate                   4.1.1\n",
            "urllib3                       1.26.14\n",
            "vega-datasets                 0.9.0\n",
            "wasabi                        0.10.1\n",
            "wcwidth                       0.2.6\n",
            "webencodings                  0.5.1\n",
            "Werkzeug                      2.2.3\n",
            "wheel                         0.38.4\n",
            "widgetsnbextension            3.6.2\n",
            "wordcloud                     1.8.2.2\n",
            "wrapt                         1.15.0\n",
            "xarray                        2022.12.0\n",
            "xarray-einstats               0.5.1\n",
            "xgboost                       1.7.4\n",
            "xkit                          0.0.0\n",
            "xlrd                          1.2.0\n",
            "xlwt                          1.3.0\n",
            "yellowbrick                   1.5\n",
            "zict                          2.2.0\n",
            "zipp                          3.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Example text data\n",
        "text_data = [\"This product is amazing and works really well.\",\n",
        "             \"I was disappointed with this product, it didn't work as expected.\",\n",
        "             \"I'm very happy with my purchase, the product exceeded my expectations.\",\n",
        "             \"This product is terrible, it doesn't work at all.\"]\n",
        "\n",
        "# BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Query\n",
        "query = \"I'm very happy with my purchase, the product works perfectly.\"\n",
        "\n",
        "# Tokenize and encode the query\n",
        "input_ids = torch.tensor(tokenizer.encode(query, add_special_tokens=True)).unsqueeze(0)\n",
        "\n",
        "# Generate the query vector\n",
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids)[0]\n",
        "    query_vector = torch.mean(last_hidden_states, dim=1).squeeze().numpy()\n",
        "\n",
        "# Compute the similarity between the query vector and each text vector\n",
        "text_vectors = []\n",
        "for text in text_data:\n",
        "    # Tokenize and encode the text\n",
        "    input_ids = torch.tensor(tokenizer.encode(text, add_special_tokens=True)).unsqueeze(0)\n",
        "    \n",
        "    # Generate the text vector\n",
        "    with torch.no_grad():\n",
        "        last_hidden_states = model(input_ids)[0]\n",
        "        text_vector = torch.mean(last_hidden_states, dim=1).squeeze().numpy()\n",
        "    \n",
        "    text_vectors.append(text_vector)\n",
        "\n",
        "# Compute the cosine similarity between the query vector and each text vector\n",
        "similarity_scores = cosine_similarity([query_vector], text_vectors)\n",
        "\n",
        "# Rank the text data based on their similarity scores\n",
        "ranked_text_data = [text_data[i] for i in similarity_scores.argsort()[0][::-1]]\n",
        "\n",
        "# Print the ranked text data\n",
        "print(\"Ranked text data based on similarity to the query:\")\n",
        "for text in ranked_text_data:\n",
        "    print(text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6kqmzN8KSbB",
        "outputId": "87ab6d00-f1b4-4406-9656-59ed737bd4f9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked text data based on similarity to the query:\n",
            "I'm very happy with my purchase, the product exceeded my expectations.\n",
            "I was disappointed with this product, it didn't work as expected.\n",
            "This product is amazing and works really well.\n",
            "This product is terrible, it doesn't work at all.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eCo1wHBDKgUn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}